## Introduction
This is the Pytorch code of LEVI-GCN as described in paper: Variational Label Enhancement (journal version).

It implements the Variational Graph Auto-Encoder (VGAE) for Label Enhancement.

This code recovers label distributions from multilabel dataset with features, logical labels and graph information.

## Environment
* Ubuntu 18.04.3 LTS
* cudatoolkit 10.1.168
* cudnn 7.6.0
* python 3.7.4
* numpy 1.17.2
* scipy 1.3.1
* torch 1.2.0

## Demo

A demo for CAL500 in classification task:

```bash
CUDA_VISIBLE_DEVICES=0 python run_main.py
```
A demo for Artificial in recovery task:

```bash
CUDA_VISIBLE_DEVICES=0 python run_main.py -t recovery -id 0 -e 45 -lr 0.001 -hidden 128 -dim_z 50 -a 0.5 -beta 1 -gamma 0.85
```

## Parameters
* `type`: The task type, either 'recovery' or 'classification'. 
Recovery task recovers the whole multilabel dataset, while classification task recovers ten-fold cross-validation datasets. 
In recovery task, code will calculate the six label distribution measures and output the enhanced label distribution datafile, while in classification task, only enhanced label distribution datafiles been outputed.
* `dataset_id`: The index of the dataset. And the dataset list with the list of feature type in classification dataset are defined in run\_main.py;
* `epochs`: Number of epochs to train (we tried epoches ranging from [100, 2000]); 
* `learning_rate`: The learning rate, we recommend a low value ranging form [0.0005, 0.001];
* `keep_prob`: The keep\_prob parameter in dropout layers, we fixed with 0.9.
* `n_hidden`: Number of the hidden nodes;
* `dim_z`: Dimension of the vairable Z (The value should not smaller than the dimension of the label);
* `alpha`: The balance parameter of the loss function;
* `beta`: The balance parameter of the loss function;
* `gamma`: The balance parameter of the loss function;
* `ld`: The balance parameter of the loss function, fixed with 1.0, while test in sensitivity analysis.
* `src_path`: Folder of the datasets of features and labels;
* `adj_path`: Folder of the datasets of graph information;
* `dst_path`: Folder of the results;
* Choose the VGAE with VGAE-Encoder (three layers, two Linear/GCN calculations, modified from original VGAE code) or VGAE-Encoder2 (four layers, three Linear/GCN calculations, modified from original LEVI-MLP code) in function main(args) in main.py

## Datafiles
* `matdata/`: The original matlab datafile, see `./matdata/README.md`; 
* `datasets/`: The dataset files should be prepared, see `./datasets/README.md`; 
* `adjmat/`: The graph information files `adjmat/[dataset]_adj.mat` should be prepared, with a #samples by #samples 0/1 adjacent matrix 'adj' for each trainset or recovery-dataset. It can be generated by finding knn used `mat_to_adj.m`, but better graph information could lead to better enhancement result.
* `results/`: The output datafiles of enhancement label distribution.

## Classification
For classification task, the enhancement label distribution will be estimated in classification scenario.
The `./Classification` is MSVR code for classification and estimation, with parameters 'C1' and 'C2', the same as 'beta' and 'gamma' described in the paper.
The ten enhanced label distribution files should be copied into `./Classification/distribution/`.
The datafiles in `./Classification/MLL_Dataset/` are the same as that in `./matdata/`.
